---
title: "Hardy-Weinberg Proportions (HWP) & Linkage Disequilibrium (LD)"
output: 
  github_document: default
  html_notebook: default
---
```{r setup, include = FALSE}
library(data.table)

```
\
First, we are going to pick up where we left off this morning thinking about expected heterozygosity, observed heterozygosity, and Hardy-Weinberg proportions (HWP). Remember that departure from HWP can indicate non-random mating, strong selection acting on a locus, or other evolutionary forces at play.
\
\
Look back to the first section of the heterozygosity lab, where we calculated the frequencies for allele 1 and allele 2, $H_{e}$ and $H_{o}$ by hand. Write these values down below
\
\
*Frequency of allele 1*: ___________________________________________________
\
\
*Frequency of allele 2*: ___________________________________________________
\
\
*$H_{e}$*: _________________________________________________________________
\
\
*$H_{o}$*: _________________________________________________________________
\
\
Open up the Excel file from the previous lab if you closed it out earlier.

## *__HWP by hand__*
\
Let's go further than judgment and see if we can construct a test for this one locus. Let's divide the samples into three genotypes: the *homozygotes* for allele 1 (the 1,1 individuals), the homozygotes for allele 2 (the 2,2 individuals) and the *heterozygotes* (the 1,2 individuals). Note that our locus has 2 alleles.
\
\
If we have Hardy-Weinberg proportions, we expect the number of homozygotes from allele 1 and allele 2 to be
\
$$E[Homozygotes_{1}] = Np_1^2 = 8p_1^2 = E_{1}$$
\
$$E[Homozygotes_{2}] = Np_2^2 = 8p_2^2 = E_{2}$$
\
where *N* is the number of individuals and the $p_{k}$s are the allele frequencies of each allele. Similarly, we expect the number of heterozygotes to be everything else, which we can calculate as
\
$$E[Heterozygotes] = N(1-\sum_{k=1}^{2}p_k^2) = 8(1 - p_1^2 - p_2^2) = E_{3}$$
\
Calculate the $E[Hom_{1}]$, $E[Hom_{2}]$ and *E[Het]* calculations using the allele frequencies you recorded above
\
\
$E[Hom_{1}] = E_{1} =$ ___________________________________________________________
\
\
$E[Hom_{2}] = E_{2} =$ ___________________________________________________________
\
\
$E[Het] = E_{3} =$ _______________________________________________________________
\
\
The observed numbers of homozygotes and heterozygotes can be found by counting them up in your file. What are they?
\
\
$O[Hom_{1}] = O_{1} =$ __________________________________________________________
\
\
$O[Hom_{2}] = O_{2} =$ __________________________________________________________
\
\
$O[Het] = O_{3} =$ ______________________________________________________________
\
\
To test whether the observed values ($O_{1}$, $O_{2}$, and $O_{3}$) match the values expected under HWP ($E_{1}$, $E_{2}$, and $E_{3}$), we use a chi-squared ($X^2$) test. The traditional $X^2$ test takes the form
\
$$X^2 = \sum_{j=1}^{3}(O_{j}-E_{j})^2/E_{j} = (O_{1}-E_{1})^2/E_{1} + (O_{2}-E_{2})^2/E_{2} + (O_{3}-E_{3})^2/E_{3}$$
\
Let's calculate that value from the data.
\
\
*What is your $X^2$ value? Show your work.*
\
\
\
\
We can compare this answer against a $X^2$-table to determine statistical significance. With three classes (two homozygote classes and one heterozygote class), we have one degree of freedom (DF). For a $X^2$ with one DF, we have a critical value of 3.84. This critical value means that a value in excess of 3.84 has only a five percent (5%) chance of occurring under the null hypothesis of HWP. We typically say that we reject the null hypothesis of HWP if $X^2$ > 3.84.
\
\
*How large is your answer, compared with the critical value of 3.84? Can we reject the null hypothesis of HWP?*
\
\
\
\
*A locus can be out of HWP due to either a heterozygote excess or a deficit. What processes could cause either a heterozygosity excess or deficit to occur in a population?*
\
\
\
\
\
\
*What process could cause one locus to be out of HWP in several populations?*
\
\
\
\
\
\
Exit out of Excel when you are done.

## *__Calculating LD__*

\
Linkage disequilibrium (also called gametic disequilibrium) is the non-random association of alleles at two different loci. For example, imagine two loci. One has alleles A and T and the other has C and G. These two loci would be in strong linkage disequilibrium if A always appears with C, and T always appears with G. We generally find stronger linkage between loci that are physically close to each other on a chromosome or in regions of a chromsome with less recombination, and between loci on which selection is acting jointly.
\
\
Open up PuTTY and log on to your Turing account. Type
```{bash, eval=FALSE}
salloc -c 12
bash -l
```
\
\
Then navigate to your workspace
```{bash, eval=FALSE}
cd /cm/shared/courses/Bioinfo_Workshop/Workspace/yourworkspace/
```
\
Today, we only want to calculate linkage disequilibrium for individuals from the Japanese population. To do so, we need to create a text file that specifies which individuals to keep and which to exclude. Create a new file by typing
```{bash, eval=FALSE}
nano J_individuals.txt
```
\
The text file is super simple : it just needs to have the names of all the individuals that we want to group together in a population. The names need to match what is in the .vcf file. Therefore, enter the following information (make sure to put each individual ID on a separate line):
```{bash, eval=FALSE}
J3
J5
J9
J11
J13
J15
J17
J19
```
\
To exit nano, look at the bottom of the screen. You will see that it says `^X` for Exit. This means `Control X`. Type that, then follow the instructions to save the file as `J_individuals.txt`.

vcftools conveniently calculates $r^2$ (a measure of LD) between pairs of loci for us. To do this type (all on one line)
```{bash, eval=FALSE}
module load vcftools/0.1
```


```{bash, eval=FALSE}
vcftools --vcf /cm/shared/courses/Bioinfo_Workshop/clownfish_data/output.hicov2.snps.only.vcf --geno-r2 --ld-window-bp 5000 --keep J_individuals.txt --out ld_J
```
\
Arguments we used:

* **--vcf** ----------- read in data from a VCF file
* **--geno-r2** ------- calculate LD as squared correlation coefficient between genotypes
* **--ld-window-bp** -- defines maximum number of bases between SNPs being tested
* **--keep** ---------- specify name of the text file with individuals to include in analysis
* **--out** ----------- specify name of output file

Now open the output file in less
```{bash, eval=FALSE}
less ld_J.geno.ld
```
\
This file is organized in columns:

* **CHR:** The name of the chromosome (or in our case, the contig from the transcriptome)
* **POS1:** The position of the first locus
* **POS2:** The position of the second locus
* **N_INDIV:** The number of individuals for which genotypes were available at these loci
* **R^2:** The squared correlation coefficient between genotypes (`-nan` means a calculation was not possible)

Remember that you can search within less by typing `/` and the search string. Since a period (.) usually means any character, you can put a `\` before a period to force less to look for an actual period, as in
```{bash, eval=FALSE}
/0\.5
```
\
to look for "0.5" in the file. You can move to the next instance of the search string by typing
```{bash, eval=FALSE}
n
```
\
*Please find five (5) pairs of loci with $r^2$ > 0.8 and list them here. (Please list both contig name and position of the SNPs.)*
\
\
\
\
*What does high LD imply about the statistical independence between the loci in each pair?*
\
\
\
\
Quit from less when you are done
```{bash, eval=FALSE}
q
```
## *__Make a plot of LD vs. distance between SNPs__*

\
We are going to make a plot from these data to show how linkage changes on average as the distance between pairs of loci increases. To do so, we will use a statistical program called R. R is very flexible and useful for a wide range of tasks, but we'll learn more about it next week. Type:
```{bash, eval=FALSE}
module load R/3.4 data.table/1.11
R
```
\
R can be customized by loading specialized functions that come in packages. We'll load one package that is useful for reading and working with large data files:
```{r, eval=FALSE}
require(data.table)
```
\
Now we'll read in the file with our LD data:
```{r, eval=FALSE}
dat <- fread("ld_J.geno.ld")
```
\
It will be easier if we remove a strange character (^) from one of the column names:
```{r, eval=FALSE}
setnames(dat, 5, "r2")
```
\
We can then calculate the $log_{10}$ distance between each pair of sites:
```{r, eval=FALSE}
dat[,logdist:=log10(abs(POS2-POS1))]
```
\
We want to calculate average LD for all pairs of loci with a similar distance apart. Here, we'll round distance down to the nearest multiple of 0.25 $log_{10}$ basepairs apart:
```{r, eval=FALSE}
dat[,distclass:=floor(logdist/0.25)*0.25+0.25/2]
```
\
We can then easily calculate average $r^2$ within each distance class:
```{r, eval=FALSE}
bins <- dat[!is.na(r2),.(r2ave=mean(r2)), by=distclass]
```
\
Now sort by distance class:
```{r, eval=FALSE}
setkey(bins, distclass)
```
\
And make a plot of average $r^2$ vs. $log_{10}$ distance! We will write the plot straight to a PDF file on Turing. The `pdf()` command starts the plot, and the `dev.off()` command ends writing to the plot.
```{r, eval=FALSE}
pdf(width=4, height=4, file="ld_decay.pdf")
bins[,plot(distclass, r2ave, type="1", xlab="Distance (log10 bp)", ylab="Average correlation (r2)", main="LD decay", xlim=c(0,3))]
dev.off()
```
\
Quit from R by typing:
```{bash, eval=FALSE}
q()
```
\
And then typing
```{bash, eval=FALSE}
n
```
\
To choose not to save your workspace (it's not necessary).
\
\
Now use WinSCP to download the pdf that you just made to your local computer. The absolute path to the pdf is
```{bash, eval=FALSE}
/cm/shared/courses/Bioinfo_Workshop/Workspace/yourworkspace/ld_decay.pdf
```
\
*Please describe how linkage between loci varies as a function of physical distance between them.*
\
\
\
\
*At what distance (in bp) does average LD flatten out to a low value?*
\
Hint: The x-axis on your graph is in $log_{10}$ bp so you will have to convert back to bp.
\
\
\
\
*We ran this analysis on data from RNAseq. How does this affect the analysis, compared to a similar analysis that might be run on RADseq or whole genome sequencing data?*